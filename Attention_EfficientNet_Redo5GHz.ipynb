{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anLbNI4MEpVG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imageio\n",
        "from scipy.ndimage import zoom\n",
        "from skimage import io\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Flatten, Dense, Activation, BatchNormalization, Add, multiply,GlobalAveragePooling2D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#################################################################\n",
        "drive.mount('/content/drive')\n",
        "# seed = 42\n",
        "# np.random.seed = seed\n",
        "\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "\n",
        "'''\n",
        "Useful blocks to build Unet\n",
        "\n",
        "conv - BN - Activation - conv - BN - Activation - Dropout (if enabled)\n",
        "\n",
        "'''\n",
        "\n",
        "input_folder1 = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Mixed_Permittivity_channel/'\n",
        "input_folder2 = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Mixed_Conductivity_channel/'\n",
        "input_folder3 = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/FSPL/'\n",
        "output_folder = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Heatmap_mixed/'\n",
        "\n",
        "# Lists to store resized images\n",
        "input_images1 = []\n",
        "input_images2 = []\n",
        "input_images3 = []\n",
        "input_tensors = []\n",
        "output_images = []\n",
        "\n",
        "# Assuming filenames in both folders are aligned\n",
        "for filename in sorted(os.listdir(input_folder1)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize input image\n",
        "        input_img_path = os.path.join(input_folder1, filename)\n",
        "        input_img1 = Image.open(input_img_path).resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "        # input_img1 = input_img1.convert('L')\n",
        "        input_images1.append(np.array(input_img1))\n",
        "\n",
        "for filename in sorted(os.listdir(input_folder2)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize input image\n",
        "        input_img_path = os.path.join(input_folder2, filename)\n",
        "        input_img2 = Image.open(input_img_path).resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "        # input_img2 = input_img2.convert('L')\n",
        "        input_images2.append(np.array(input_img2))\n",
        "\n",
        "for filename in sorted(os.listdir(input_folder3)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize input image\n",
        "        input_img_path = os.path.join(input_folder3, filename)\n",
        "        input_img3 = Image.open(input_img_path).resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "        input_img3 = input_img3.convert('L')\n",
        "        input_images3.append(np.array(input_img3))\n",
        "\n",
        "for i in range(0, 2997, 999):\n",
        "    for j in range(999):\n",
        "        # Stacking images from input_folder1, input_folder2, and the corresponding image from folder3\n",
        "        combined = np.stack((input_images1[i+j], input_images2[i+j], input_images3[i//999]), axis=-1)\n",
        "        input_tensors.append(combined)\n",
        "\n",
        "X_allset = np.array(input_tensors)\n",
        "\n",
        "for filename in sorted(os.listdir(output_folder)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize corresponding output image\n",
        "        output_img_path = os.path.join(output_folder, filename)  # assuming the naming is consistent\n",
        "        output_img = Image.open(output_img_path).resize((IMG_WIDTH//2,IMG_HEIGHT//2))\n",
        "        # output_img = Image.open(output_img_path).resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "        output_images.append(np.array(output_img))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "Y_allset = np.array(output_images)\n",
        "# Generate shuffled indices\n",
        "indices = np.arange(X_allset.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "X_allset_shuffled = X_allset[indices]\n",
        "Y_allset_shuffled = Y_allset[indices]\n",
        "TrainingSize = 2900\n",
        "X_train = X_allset_shuffled[:TrainingSize]\n",
        "Y_train = Y_allset_shuffled[:TrainingSize]\n",
        "\n",
        "X_test = X_allset_shuffled[TrainingSize:]\n",
        "Y_test = Y_allset_shuffled[TrainingSize:]\n",
        "\n",
        "print(indices[2996])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GxRh4wTNEs6m"
      },
      "outputs": [],
      "source": [
        "########################################################################################\n",
        "def repeat_elem(tensor, rep):\n",
        "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
        "    #by a factor of rep.\n",
        "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n",
        "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
        "\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False,reg=l2(0.001)):\n",
        "    '''\n",
        "    Residual convolutional layer.\n",
        "    Two variants....\n",
        "    Either put activation function before the addition with shortcut\n",
        "    or after the addition (which would be as proposed in the original resNet).\n",
        "\n",
        "    1. conv - BN - Activation - conv - BN - Activation\n",
        "                                          - shortcut  - BN - shortcut+BN\n",
        "\n",
        "    2. conv - BN - Activation - conv - BN\n",
        "                                     - shortcut  - BN - shortcut+BN - Activation\n",
        "\n",
        "    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
        "    '''\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', kernel_regularizer=reg)(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation('relu')(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', kernel_regularizer=reg)(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same', kernel_regularizer=reg)(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = layers.add([shortcut, conv])\n",
        "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
        "    return res_path\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    \"\"\"\n",
        "    resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    using 1x1 conv\n",
        "    :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                #  strides=(1,1),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n",
        "\n",
        "# Specify the L2 regularization factor\n",
        "l2_reg = 0.01\n",
        "\n",
        "def Attention_EfficientUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True,reg=l2(l2_reg)):\n",
        "    '''\n",
        "    Efficient UNet, with attention\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    # dimension of the image depth\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    efficientnetb5 = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    for layer in efficientnetb5.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # You need to find out the equivalent layers in EfficientNet B7\n",
        "    # For example, let's assume you've identified the layers in EfficientNet B7 that you want to use\n",
        "    conv_128 = efficientnetb5.get_layer('block2a_expand_activation').output  # Example layer\n",
        "    conv_64 = efficientnetb5.get_layer('block3a_expand_activation').output   # Example layer\n",
        "    conv_32 = efficientnetb5.get_layer('block4a_expand_activation').output   # Example layer\n",
        "    conv_16 = efficientnetb5.get_layer('block5a_expand_activation').output   # Example layer\n",
        "\n",
        "    # Bridge\n",
        "    bridge = efficientnetb5.get_layer('top_activation').output\n",
        "    # print(\"conv_128:\", K.int_shape(conv_128))\n",
        "    # print(\"conv_64:\", K.int_shape(conv_64))\n",
        "    # print(\"conv_32:\", K.int_shape(conv_32))\n",
        "    # print(\"conv_16:\", K.int_shape(conv_16))\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(bridge, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(bridge)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=axis)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm, reg=reg)\n",
        "    # print(\"gating_16:\", K.int_shape(gating_16))\n",
        "    # print(\"att_16:\", K.int_shape(att_16))\n",
        "    # print(\"up_16:\", K.int_shape(up_16))\n",
        "    # print(\"up_conv_16:\", K.int_shape(up_conv_16))\n",
        "\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm, reg=reg)\n",
        "    # print(\"gating_32:\", K.int_shape(gating_32))\n",
        "    # print(\"att_32:\", K.int_shape(att_32))\n",
        "    # print(\"up_32:\", K.int_shape(up_32))\n",
        "    # print(\"up_conv_32:\", K.int_shape(up_conv_32))\n",
        "\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm, reg=reg)\n",
        "    # print(\"gating_64:\", K.int_shape(gating_64))\n",
        "    # print(\"att_64:\", K.int_shape(att_64))\n",
        "    # print(\"up_64:\", K.int_shape(up_64))\n",
        "    # print(\"up_conv_64:\", K.int_shape(up_conv_64))\n",
        "\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm, reg=reg)\n",
        "    # print(\"gating_128:\", K.int_shape(gating_128))\n",
        "    # print(\"att_128:\", K.int_shape(att_128))\n",
        "    # print(\"up_128:\", K.int_shape(up_128))\n",
        "    # print(\"up_conv_128:\", K.int_shape(up_conv_128))\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1), kernel_regularizer=reg)(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = layers.Activation('linear')(conv_final)  #Change to softmax for multichannel\n",
        "    # print(\"conv_final:\", K.int_shape(conv_final))\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"AttentionResUNet\")\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "input_shape = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS)\n",
        "model = Attention_EfficientUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.5, batch_norm=True)\n",
        "# model.summary()\n",
        "# learning_rate_start = 1e0\n",
        "# learning_rate_end =   1e-8\n",
        "learning_rate_start = 1e-2\n",
        "learning_rate_end =   1e-4\n",
        "decay_steps = 1500\n",
        "# Define the polynomial decay\n",
        "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=learning_rate_start,\n",
        "    decay_steps=decay_steps,\n",
        "    end_learning_rate=learning_rate_end,\n",
        "    power=1.0  # This makes it a linear decay\n",
        ")\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9), loss='mean_squared_error', metrics=['accuracy'])\n",
        "# Check the size of the training datas\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(\"Input shape:\", model.output_shape)\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-a4TY6mEvB2"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "# Training The 1st Leg\n",
        "##################################################\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_floorplan.h5', verbose=1, save_best_only=True)\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
        "        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
        "\n",
        "# results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=20, epochs=200, callbacks=callbacks)\n",
        "\n",
        "# Fit the model and save the history\n",
        "history = model.fit(X_train, Y_train, validation_split=0.3, batch_size=32, epochs=30, callbacks=callbacks)\n",
        "# model.save('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttnUnet_5GHz_1st_leg.keras')\n",
        "# Training Error: Mean Squared Error\n",
        "training_error = history.history['loss']\n",
        "\n",
        "# Validation Error: Mean Squared Error on the validation set\n",
        "validation_error = history.history['val_loss']\n",
        "\n",
        "# Calculate the number of epochs actually run\n",
        "epochs_run = range(len(training_error))\n",
        "\n",
        "# Set a threshold for the training and validation error in order to plot a sensible figure\n",
        "threshold = 1800\n",
        "training_error = [min(error, threshold) for error in training_error]\n",
        "validation_error = [min(error, threshold) for error in validation_error]\n",
        "\n",
        "# Plot training & validation errors\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_run, training_error, 'g-', label='Training error')\n",
        "plt.plot(epochs_run, validation_error, 'r-', label='Validation error')\n",
        "plt.title('Training and Validation error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print('Training error:',training_error[-1])\n",
        "print('Validation error:',validation_error[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKgHl83CEwzO"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# In terms of the 1st leg\n",
        "# Plot the training sample\n",
        "#####################################################\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttnUnet_5GHz_1st_leg.keras', safe_mode=False)\n",
        "i=0\n",
        "# Extract the first sample\n",
        "first_sample = X_train[i]\n",
        "# Expand dimensions to simulate a batch of size 1\n",
        "first_sample = np.expand_dims(first_sample, axis=0)  # first_sample.shape = (1, 256, 256, 3)\n",
        "# Predict\n",
        "prediction = model.predict(first_sample)\n",
        "# Resize the coverage map to its original size\n",
        "prediction_resized = zoom(prediction.squeeze(), (65/prediction.shape[1], 115/prediction.shape[2]))\n",
        "Y_train_resized = zoom(Y_train[i].squeeze(), (65/Y_train[i].shape[0], 115/Y_train[i].shape[1]))\n",
        "\n",
        "# Define the color map\n",
        "cmap = plt.cm.jet\n",
        "\n",
        "# Determine the range of your data for consistent color mapping\n",
        "combined = np.concatenate((prediction_resized.flatten(), Y_train_resized.flatten()))\n",
        "min_val = combined.min()\n",
        "max_val = combined.max()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Display the prediction heatmap\n",
        "cax1 = axes[0].imshow(prediction_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[0].set_title(\"Prediction\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Display the ground truth heatmap\n",
        "cax2 = axes[1].imshow(Y_train_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[1].set_title('RT Simulation')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Add colorbar, make sure to specify the ticks you want to display\n",
        "# and their corresponding labels\n",
        "colorbar = fig.colorbar(cax2, ax=axes.ravel().tolist(), orientation='horizontal', fraction=0.046, pad=0.04)\n",
        "colorbar.set_label('Signal Strength (dBm)')\n",
        "colorbar.set_ticks([min_val, max_val])\n",
        "colorbar.set_ticklabels(['-125.5 dBm', '-54.6 dBm'])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Numberical results including RMSE and CDF plot\n",
        "squared_differences_train = (prediction.squeeze()- Y_train[i])**2\n",
        "rmse_train = np.sqrt(squared_differences_train.mean())\n",
        "\n",
        "difference = np.abs(prediction.squeeze()- Y_train[i])\n",
        "flattened_diff = difference.flatten()\n",
        "\n",
        "# Calculate the CDF\n",
        "hist, bin_edges = np.histogram(flattened_diff, bins=256, range=(0, 256), density=True)\n",
        "cdf = np.cumsum(hist) * np.diff(bin_edges)\n",
        "# Plot the CDF\n",
        "plt.plot(cdf, color='blue')\n",
        "plt.title('CDF of Image Difference')\n",
        "plt.xlabel('Pixel Intensity Difference')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"RMSE of Training Sample:\", rmse_train)\n",
        "\n",
        "import scipy.io as sio\n",
        "from google.colab import files\n",
        "sio.savemat('prediction_resized.mat', {'prediction_resized': prediction_resized})\n",
        "files.download('prediction_resized.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tD6EiCvkEyJ-"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# In terms of the 1st leg\n",
        "# Plot the testing sample\n",
        "#####################################################\n",
        "\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttentionUnet_Furniture_Mixed.keras')\n",
        "# Calculating Overall Testing Error\n",
        "# First, obtain predictions for the testing set\n",
        "predictions = model.predict(X_test)\n",
        "# Ensure that predictions and Y_test are reshaped or flattened if they are multi-dimensional, to compute RMSE correctly\n",
        "predictions = predictions.flatten()\n",
        "actuals = Y_test.flatten()\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actuals, predictions)\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Overall Testing Error (RMSE):\", rmse)\n",
        "\n",
        "i=0\n",
        "first_sample = X_test[i]\n",
        "first_sample = np.expand_dims(first_sample, axis=0)  # first_sample.shape = (1, 256, 256, 3)\n",
        "prediction = model.predict(first_sample)\n",
        "prediction_resized = zoom(prediction.squeeze(), (65/prediction.shape[1], 115/prediction.shape[2]))\n",
        "Y_test_resized = zoom(Y_test[i].squeeze(), (65/Y_test[i].shape[0], 115/Y_test[i].shape[1]))\n",
        "# Define the color map\n",
        "cmap = plt.cm.jet\n",
        "\n",
        "# Determine the range of your data for consistent color mapping\n",
        "combined = np.concatenate((prediction_resized.flatten(), Y_test_resized.flatten()))\n",
        "min_val = combined.min()\n",
        "max_val = combined.max()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Display the prediction heatmap\n",
        "cax1 = axes[0].imshow(prediction_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[0].set_title(\"Prediction\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Display the ground truth heatmap\n",
        "cax2 = axes[1].imshow(Y_test_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[1].set_title('RT Simulation')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Add colorbar, make sure to specify the ticks you want to display\n",
        "# and their corresponding labels\n",
        "colorbar = fig.colorbar(cax2, ax=axes.ravel().tolist(), orientation='horizontal', fraction=0.046, pad=0.04)\n",
        "colorbar.set_label('Signal Strength (dBm)')\n",
        "colorbar.set_ticks([min_val, max_val])\n",
        "colorbar.set_ticklabels(['-125.5 dBm', '-54.6 dBm'])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Numberical results including RMSE and CDF plot\n",
        "squared_differences_test = (prediction.squeeze()- Y_test[i])**2\n",
        "rmse_test = np.sqrt(squared_differences_test.mean())\n",
        "difference = np.abs(prediction.squeeze()- Y_test[i])\n",
        "flattened_diff = difference.flatten()\n",
        "\n",
        "# Calculate the CDF\n",
        "hist, bin_edges = np.histogram(flattened_diff, bins=256, range=(0, 256), density=True)\n",
        "cdf = np.cumsum(hist) * np.diff(bin_edges)\n",
        "# Plot the CDF\n",
        "plt.plot(cdf, color='blue')\n",
        "plt.title('CDF of Image Difference')\n",
        "plt.xlabel('Pixel Intensity Difference')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"RMSE of Testing Sample:\", rmse_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eE1m6hhWEzu_"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# Save the corase prediction from 1st leg to dir: .../Coarse Pred\n",
        "#####################################################\n",
        "# model = tf.keras.models.load_model('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttnResUnet_Furniture_Mixed_2.0.keras', safe_mode=False)\n",
        "\n",
        "# Directory where you want to save the predicted images\n",
        "save_dir = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Coarse Pred/'\n",
        "# Loop through all the files in the folder\n",
        "# Delete the folder if it exists\n",
        "if os.path.exists(save_dir):\n",
        "    shutil.rmtree(save_dir)\n",
        "    print(f\"Deleted the folder: {save_dir}\")\n",
        "\n",
        "# Create the folder\n",
        "os.makedirs(save_dir)\n",
        "print(f\"Created a new folder: {save_dir}\")\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Iterate over your images in X_Train and predict\n",
        "for i, image in enumerate(X_train, start=0):\n",
        "    print(f\"Processing image {i+1}/{len(X_train)}...\")\n",
        "    # Ensure the image is normalized if your model expects that\n",
        "    image = X_train[i]\n",
        "\n",
        "    # Predict the image (add batch dimension since model expects it)\n",
        "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "    # Assuming the prediction is an image\n",
        "    predicted_image = prediction.squeeze()  # Remove the batch dimension\n",
        "    # predicted_image = (predicted_image * 255).astype(np.uint8)  # Convert back to image format if necessary\n",
        "\n",
        "    # Save the predicted image\n",
        "    save_path = os.path.join(save_dir, f\"Coarse Pred_{i}.jpg\")\n",
        "    cv2.imwrite(save_path, predicted_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EvDP7CkE2wv"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# Read the results from 1st leg, and make it as the input for the 2nd leg\n",
        "#####################################################\n",
        "\n",
        "input_folder4 = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Coarse Pred/'\n",
        "input_images4 = []\n",
        "input_tensors_2nd_leg = []\n",
        "for filename in sorted(os.listdir(input_folder4)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize input image\n",
        "        input_img_path = os.path.join(input_folder4, filename)\n",
        "        input_img4 = Image.open(input_img_path)\n",
        "        # input_img4 = input_img4.convert('L')\n",
        "        input_images4.append(np.array(input_img4))\n",
        "\n",
        "upsampled_input_images4 = []\n",
        "\n",
        "# Assuming input_images4 is a list of numpy arrays\n",
        "for image in input_images4:\n",
        "    # Convert the numpy array image back to a PIL image\n",
        "    img = Image.fromarray(image)\n",
        "\n",
        "    # Resize the image using PIL's resize method. You can change the resampling filter as needed.\n",
        "    # Image.BILINEAR, Image.BICUBIC, and Image.LANCZOS are other options.\n",
        "    upsampled_img = img.resize((256, 256), Image.NEAREST)\n",
        "\n",
        "    # Convert the PIL image back to a numpy array if needed\n",
        "    upsampled_input_images4.append(np.array(upsampled_img))\n",
        "\n",
        "# If you need the result as a numpy array\n",
        "upsampled_input_images4 = np.array(upsampled_input_images4)\n",
        "\n",
        "input_1 = X_train[:,:,:,1]\n",
        "input_2 = X_train[:,:,:,2]\n",
        "for i in range(0, 2900):\n",
        "    # Stacking images from input_folder1, input_folder2, and the corresponding image from folder3\n",
        "    combined = np.stack((input_1[i], input_2[i], upsampled_input_images4[i]), axis=-1)\n",
        "    input_tensors_2nd_leg.append(combined)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "\n",
        "X_allset_2nd_leg = np.array(input_tensors_2nd_leg)\n",
        "\n",
        "X_train_2nd_leg = X_allset_2nd_leg\n",
        "Y_train_2nd_leg = Y_train\n",
        "\n",
        "print(X_train_2nd_leg.shape)\n",
        "print(Y_train_2nd_leg.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euDRlN65SDwI"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# Training the 2nd leg\n",
        "#####################################################\n",
        "\n",
        "# model_2nd_leg = Attention_EfficientUNet(input_shape, NUM_CLASSES=1, dropout_rate=0.5, batch_norm=True)\n",
        "learning_rate_start = 1e-4\n",
        "learning_rate_end =   1e-6\n",
        "decay_steps = 1500\n",
        "# Define the polynomial decay\n",
        "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=learning_rate_start,\n",
        "    decay_steps=decay_steps,\n",
        "    end_learning_rate=learning_rate_end,\n",
        "    power=1.0  # This makes it a linear decay\n",
        ")\n",
        "\n",
        "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
        "model_2nd_leg.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_floorplan.h5', verbose=1, save_best_only=True)\n",
        "callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
        "        tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
        "\n",
        "# results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=20, epochs=200, callbacks=callbacks)\n",
        "\n",
        "# Fit the model and save the history\n",
        "history = model_2nd_leg.fit(X_train_2nd_leg, Y_train_2nd_leg, validation_split=0.3, batch_size=32, epochs=30, callbacks=callbacks)\n",
        "model_2nd_leg.save('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttnUnet_5GHz_2nd_leg.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8v96A6QbFgg"
      },
      "outputs": [],
      "source": [
        "# Compute Overall Training Error\n",
        "predictions_2nd_leg = model_2nd_leg.predict(X_train_2nd_leg)\n",
        "# Ensure that predictions and Y_test are reshaped or flattened if they are multi-dimensional, to compute RMSE correctly\n",
        "predictions_2nd_leg = predictions_2nd_leg.flatten()\n",
        "actuals = Y_train_2nd_leg.flatten()\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actuals, predictions_2nd_leg)\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Overall Testing Error (RMSE):\", rmse)\n",
        "# Compute MAE\n",
        "mae = np.mean(np.abs(actuals - predictions_2nd_leg))\n",
        "print(\"Overall Training Error (MAE):\", mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He6fOjTSWrKZ"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# IN terms of the 2nd leg. Plot the training sample\n",
        "#####################################################\n",
        "model_2nd_leg = tf.keras.models.load_model('/content/drive/MyDrive/CNN data/Redo_5GHz/Low/Model_AttnUnet_5GHz_2nd_leg.keras', safe_mode=False)\n",
        "i=0\n",
        "# Extract the first sample\n",
        "first_sample = X_train_2nd_leg[i]\n",
        "# Expand dimensions to simulate a batch of size 1\n",
        "first_sample = np.expand_dims(first_sample, axis=0)  # first_sample.shape = (1, 256, 256, 3)\n",
        "\n",
        "# Predict\n",
        "prediction = model_2nd_leg.predict(first_sample)\n",
        "\n",
        "# Resize the coverage map to its original size\n",
        "prediction_resized = zoom(prediction.squeeze(), (65/prediction.shape[1], 115/prediction.shape[2]))\n",
        "Y_train_2nd_leg_resized = zoom(Y_train_2nd_leg[i].squeeze(), (65/Y_train_2nd_leg[i].shape[0], 115/Y_train_2nd_leg[i].shape[1]))\n",
        "\n",
        "\n",
        "# Define the color map\n",
        "cmap = plt.cm.jet\n",
        "\n",
        "# Determine the range of your data for consistent color mapping\n",
        "combined = np.concatenate((prediction_resized.flatten(), Y_train_2nd_leg_resized.flatten()))\n",
        "min_val = combined.min()\n",
        "max_val = combined.max()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Display the prediction heatmap\n",
        "cax1 = axes[0].imshow(prediction_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[0].set_title(\"Prediction\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Display the ground truth heatmap\n",
        "cax2 = axes[1].imshow(Y_train_2nd_leg_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[1].set_title('RT Simulation')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Add colorbar, make sure to specify the ticks you want to display\n",
        "# and their corresponding labels\n",
        "colorbar = fig.colorbar(cax2, ax=axes.ravel().tolist(), orientation='horizontal', fraction=0.046, pad=0.04)\n",
        "colorbar.set_label('Signal Strength (dBm)')\n",
        "colorbar.set_ticks([min_val, max_val])\n",
        "colorbar.set_ticklabels(['-125.5 dBm', '-54.6 dBm'])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Numberical results including RMSE and CDF plot\n",
        "squared_differences_train = (prediction.squeeze()- Y_train_2nd_leg[i])**2\n",
        "rmse_train = np.sqrt(squared_differences_train.mean())\n",
        "\n",
        "difference = np.abs(prediction.squeeze()- Y_train_2nd_leg[i])\n",
        "flattened_diff = difference.flatten()\n",
        "\n",
        "# Calculate the CDF\n",
        "hist, bin_edges = np.histogram(flattened_diff, bins=256, range=(0, 256), density=True)\n",
        "cdf = np.cumsum(hist) * np.diff(bin_edges)\n",
        "# Plot the CDF\n",
        "plt.plot(cdf, color='blue')\n",
        "plt.title('CDF of Image Difference')\n",
        "plt.xlabel('Pixel Intensity Difference')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"RMSE of Training Sample:\", rmse_train)\n",
        "\n",
        "\n",
        "import scipy.io as sio\n",
        "from google.colab import files\n",
        "sio.savemat('prediction_resized.mat', {'prediction_resized': prediction_resized})\n",
        "sio.savemat('Y_train_resized.mat', {'Y_train_resized': Y_train_resized})\n",
        "files.download('Y_train_resized.mat')\n",
        "files.download('prediction_resized.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_SFbIAQaXzTQ"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# Predicting the Testing samples, on 1st leg, and make it to be the input to the 2nd leg\n",
        "#####################################################\n",
        "\n",
        "# Predicting the corase images with the 1st leg\n",
        "save_dir = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/SR Pred/'\n",
        "if os.path.exists(save_dir):\n",
        "    shutil.rmtree(save_dir)\n",
        "    print(f\"Deleted the folder: {save_dir}\")\n",
        "\n",
        "# Create the folder\n",
        "os.makedirs(save_dir)\n",
        "print(f\"Created a new folder: {save_dir}\")\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Iterate over your images in X_Train and predict\n",
        "for i, image in enumerate(X_test, start=0):\n",
        "    print(f\"Processing image {i+1}/{len(X_test)}...\")\n",
        "    # Ensure the image is normalized if your model expects that\n",
        "    image = X_test[i]\n",
        "\n",
        "    # Predict the image (add batch dimension since model expects it)\n",
        "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
        "\n",
        "    # Assuming the prediction is an image\n",
        "    predicted_image = prediction.squeeze()  # Remove the batch dimension\n",
        "    # predicted_image = (predicted_image * 255).astype(np.uint8)  # Convert back to image format if necessary\n",
        "\n",
        "    # Save the predicted image\n",
        "    save_path = os.path.join(save_dir, f\"SR Pred_{i}.jpg\")\n",
        "    cv2.imwrite(save_path, predicted_image)\n",
        "\n",
        "####################################################################\n",
        "# Read the coarse images from 1st let, and make it as the input to the 2nd leg\n",
        "\n",
        "input_folder5 = '/content/drive/MyDrive/CNN data/Redo_5GHz/Low/SR Pred/'\n",
        "input_images5 = []\n",
        "input_tensors_2nd_leg_test = []\n",
        "for filename in sorted(os.listdir(input_folder5)):\n",
        "    if filename.endswith(\".jpg\") :  # adjust as needed\n",
        "        # Read and resize input image\n",
        "        input_img_path = os.path.join(input_folder5, filename)\n",
        "        input_img5 = Image.open(input_img_path)\n",
        "        # input_img4 = input_img4.convert('L')\n",
        "        input_images5.append(np.array(input_img5))\n",
        "\n",
        "upsampled_input_images5 = []\n",
        "\n",
        "# Assuming input_images4 is a list of numpy arrays\n",
        "for image in input_images5:\n",
        "    # Convert the numpy array image back to a PIL image\n",
        "    img = Image.fromarray(image)\n",
        "\n",
        "    # Resize the image using PIL's resize method. You can change the resampling filter as needed.\n",
        "    # Image.BILINEAR, Image.BICUBIC, and Image.LANCZOS are other options.\n",
        "    upsampled_img_test = img.resize((256, 256), Image.NEAREST)\n",
        "\n",
        "    # Convert the PIL image back to a numpy array if needed\n",
        "    upsampled_input_images5.append(np.array(upsampled_img_test))\n",
        "\n",
        "# If you need the result as a numpy array\n",
        "upsampled_input_images5 = np.array(upsampled_input_images5)\n",
        "\n",
        "input_1 = X_test[:,:,:,1]\n",
        "input_2 = X_test[:,:,:,2]\n",
        "for i in range(0, 97):\n",
        "    # Stacking images from input_folder1, input_folder2, and the corresponding image from folder3\n",
        "    combined = np.stack((input_1[i], input_2[i], upsampled_input_images5[i]), axis=-1)\n",
        "    input_tensors_2nd_leg_test.append(combined)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "\n",
        "input_sample_test = np.array(input_tensors_2nd_leg_test)\n",
        "print(upsampled_input_images5.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syDxrDmeny8c"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "# Plot the test sample, which are the final results\n",
        "#####################################################\n",
        "# Calculating Overall Testing Error\n",
        "# First, obtain predictions for the testing set\n",
        "predictions_2nd_leg = model_2nd_leg.predict(input_sample_test)\n",
        "# Ensure that predictions and Y_test are reshaped or flattened if they are multi-dimensional, to compute RMSE correctly\n",
        "predictions_2nd_leg = predictions_2nd_leg.flatten()\n",
        "actuals = Y_test.flatten()\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actuals, predictions_2nd_leg)\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"Overall Testing Error (RMSE):\", rmse)\n",
        "# Compute MAE\n",
        "mae = np.mean(np.abs(actuals - predictions_2nd_leg))\n",
        "print(\"Overall Training Error (MAE):\", mae)\n",
        "\n",
        "i=2\n",
        "# Extract the first sample\n",
        "first_sample_test = input_sample_test[i]\n",
        "# Expand dimensions to simulate a batch of size 1\n",
        "first_sample_test = np.expand_dims(first_sample_test, axis=0)  # first_sample.shape = (1, 256, 256, 3)\n",
        "print(first_sample_test.shape )\n",
        "# Predict\n",
        "prediction_test = model_2nd_leg.predict(first_sample_test)\n",
        "\n",
        "# Resize the coverage map to its original size\n",
        "prediction_test_resized = zoom(prediction_test.squeeze(), (65/prediction_test.shape[1], 115/prediction_test.shape[2]))\n",
        "Y_test_resized = zoom(Y_test[i].squeeze(), (65/Y_test[i].shape[0], 115/Y_test[i].shape[1]))\n",
        "\n",
        "# Define the color map\n",
        "cmap = plt.cm.jet\n",
        "\n",
        "# Determine the range of your data for consistent color mapping\n",
        "combined = np.concatenate((prediction_test_resized.flatten(), Y_test_resized.flatten()))\n",
        "min_val = combined.min()\n",
        "max_val = combined.max()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Display the prediction heatmap\n",
        "cax1 = axes[0].imshow(prediction_test_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[0].set_title(\"Prediction\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Display the ground truth heatmap\n",
        "cax2 = axes[1].imshow(Y_test_resized, interpolation='nearest', cmap=cmap, vmin=min_val, vmax=max_val)\n",
        "axes[1].set_title('RT Simulation')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Add colorbar, make sure to specify the ticks you want to display\n",
        "# and their corresponding labels\n",
        "colorbar = fig.colorbar(cax2, ax=axes.ravel().tolist(), orientation='horizontal', fraction=0.046, pad=0.04)\n",
        "colorbar.set_label('Signal Strength (dBm)')\n",
        "colorbar.set_ticks([min_val, max_val])\n",
        "colorbar.set_ticklabels(['-125.5 dBm', '-54.6 dBm'])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Numberical results including RMSE and CDF plot\n",
        "squared_differences_train = (prediction_test.squeeze()- Y_test[i])**2\n",
        "rmse_train = np.sqrt(squared_differences_train.mean())\n",
        "\n",
        "difference = np.abs(prediction_test.squeeze()- Y_test[i])\n",
        "flattened_diff = difference.flatten()\n",
        "\n",
        "# Calculate the CDF\n",
        "hist, bin_edges = np.histogram(flattened_diff, bins=256, range=(0, 256), density=True)\n",
        "cdf = np.cumsum(hist) * np.diff(bin_edges)\n",
        "# Plot the CDF\n",
        "plt.plot(cdf, color='blue')\n",
        "plt.title('CDF of Image Difference')\n",
        "plt.xlabel('Pixel Intensity Difference')\n",
        "plt.ylabel('Cumulative Probability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"RMSE of Training Sample:\", rmse_train)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyPLFta2vIKmql4RtQt+V5yt"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}